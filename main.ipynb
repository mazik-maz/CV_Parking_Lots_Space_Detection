{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "\n",
    "frames_folder = 'images/train'\n",
    "empty_parking_folder = 'final_base'\n",
    "output = 'output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspective_transform(image, src_points, dst_points):\n",
    "    matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "    warped = cv2.warpPerspective(image, matrix, (image.shape[1], image.shape[0]))\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_best_blur(image, method=\"gaussian\", kernel_size=3, sigma=0, diameter=9, sigma_color=200, sigma_space=200):\n",
    "    if method == \"gaussian\":\n",
    "        blurred_image = cv2.GaussianBlur(image, (kernel_size, kernel_size), sigma)\n",
    "    elif method == \"median\":\n",
    "        blurred_image = cv2.medianBlur(image, kernel_size)\n",
    "    elif method == \"bilateral\":\n",
    "        blurred_image = cv2.bilateralFilter(image, diameter, sigma_color, sigma_space)\n",
    "    else:\n",
    "        raise ValueError(\"incorrect method\")\n",
    "    \n",
    "    return blurred_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_in_row(list_of_images, titles = None, disable_ticks = False):\n",
    "    count = len(list_of_images)\n",
    "    for idx in range(count):\n",
    "        subplot = plt.subplot(1, count, idx+1)\n",
    "        if titles is not None:\n",
    "            subplot.set_title(titles[idx])\n",
    "\n",
    "        img = list_of_images[idx]\n",
    "        cmap = 'gray' if (len(img.shape) == 2 or img.shape[2] == 1) else None\n",
    "        subplot.imshow(img, cmap=cmap)\n",
    "        if disable_ticks:\n",
    "            plt.xticks([]), plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_match(imageA, imageB):\n",
    "    err = np.mean((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "    \n",
    "    return err <= 1200.0\n",
    "\n",
    "def images_match(img1, img2, method=cv2.TM_CCOEFF_NORMED, threshold=0.8):\n",
    "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
    "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    res = cv2.matchTemplate(img2_gray, img1_gray, method)\n",
    "    min_val, max_val, _, _ = cv2.minMaxLoc(res)\n",
    "\n",
    "    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "        match_value = min_val\n",
    "        # For these methods, lower values indicate a better match\n",
    "        match = match_value <= (1 - threshold)\n",
    "    else:\n",
    "        match_value = max_val\n",
    "        # For these methods, higher values indicate a better match\n",
    "        match = match_value >= threshold\n",
    "\n",
    "    return match\n",
    "\n",
    "def images_match_ncc(img1, img2, threshold=0.2):\n",
    "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
    "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    ncc = np.corrcoef(img2_gray, img1_gray)\n",
    "\n",
    "    return ncc[0, -1] >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_spaces = np.float32([\n",
    "    [[121, 74], [130, 73], [116, 86], [125, 86]],\n",
    "    [[142, 146], [155, 145], [136, 165], [150, 165]],\n",
    "    [[95, 102], [106, 101], [88, 119], [99, 118]],\n",
    "    [[85, 453], [106, 453], [72, 494], [96, 494]],\n",
    "    [[109, 454], [130, 454], [99, 493], [121, 494]],\n",
    "    [[135, 454], [155, 454], [124, 495], [146, 495]],\n",
    "    [[159, 456], [181, 456], [149, 495], [173, 496]],\n",
    "    [[184, 455], [208, 454], [177, 495], [202, 495]],\n",
    "    [[212, 455], [235, 455], [205, 495], [228, 495]],\n",
    "\n",
    "    [[70, 80], [79, 80], [61, 95], [70, 95]],\n",
    "    [[81, 80], [90, 80], [76, 94], [85, 92]],\n",
    "    [[94, 80], [103, 80], [89, 91], [98, 91]],\n",
    "    [[108, 77], [116, 77], [103, 89], [111, 88]],\n",
    "    [[119, 75], [129, 74], [115, 89], [124, 88]],\n",
    "    [[132, 74], [141, 74], [127, 87], [137, 87]],\n",
    "    [[145, 74], [154, 74], [140, 87], [150, 86]],\n",
    "    [[158, 72], [167, 72], [153, 86], [163, 86]],\n",
    "    [[171, 72], [181, 72], [167, 86], [176, 86]],\n",
    "    [[185, 72], [194, 72], [180, 86], [191, 86]],\n",
    "    [[198, 72], [208, 72], [194, 86], [204, 86]],\n",
    "    [[211, 72], [220, 72], [208, 85], [218, 85]],\n",
    "    [[224, 72], [235, 72], [220, 85], [232, 85]],\n",
    "    [[239, 72], [248, 72], [236, 84], [246, 84]],\n",
    "    [[260, 70], [270, 70], [258, 83], [267, 83]],\n",
    "    [[275, 69], [285, 69], [271, 82], [283, 82]],\n",
    "    [[289, 67], [300, 67], [288, 81], [297, 81]],\n",
    "    [[304, 66], [314, 66], [301, 81], [311, 81]],\n",
    "    # [[, ], [, ], [, ], [, ]],\n",
    "    # [[, ], [, ], [, ], [, ]],\n",
    "    # [[, ], [, ], [, ], [, ]],\n",
    "    # [[, ], [, ], [, ], [, ]],\n",
    "    # [[, ], [, ], [, ], [, ]],\n",
    "    # [[, ], [, ], [, ], [, ]],\n",
    "    # [[, ], [, ], [, ], [, ]],\n",
    "\n",
    "    \n",
    "    [[105, 15], [115, 15], [99, 32], [109, 32]],\n",
    "    [[91, 40], [103, 40], [85, 57], [97, 57]],\n",
    "    [[70, 81], [82, 81], [61, 98], [75, 98]],\n",
    "    [[59, 104], [71, 105], [48, 125], [61, 125]],\n",
    "    [[34, 154], [45, 155], [21, 179], [33, 179]],\n",
    "    [[16, 187], [30, 187], [5, 208], [19, 209]],\n",
    "\n",
    "    [[13, 252], [25, 252], [2, 275], [15, 275]],\n",
    "\n",
    "    [[28, 252], [40, 252], [17, 275], [30, 275]], \n",
    "    [[45, 251], [57, 251], [34, 274], [47, 274]],\n",
    "    [[60, 251], [72, 251], [49, 274], [62, 274]], #<-\n",
    "    [[73, 250], [85, 250], [62, 273], [75, 273]],\n",
    "    [[88, 250], [100, 250], [77, 273], [90, 273]],\n",
    "    [[103, 249], [115, 249], [92, 273], [105, 273]],\n",
    "    [[118, 249], [130, 249], [107, 273], [120, 273]],\n",
    "    [[133, 248], [145, 248], [122, 273], [135, 273]],\n",
    "    [[148, 248], [160, 248], [137, 273], [150, 273]],\n",
    "    [[163, 247], [175, 247], [152, 273], [165, 273]],\n",
    "    [[178, 247], [190, 247], [167, 273], [180, 273]],\n",
    "    [[193, 246], [205, 246], [182, 273], [195, 273]],\n",
    "    [[208, 246], [220, 246], [197, 273], [180, 273]],\n",
    "\n",
    "    [[222, 248], [235, 248], [218, 272], [231, 272]],\n",
    "    \n",
    "    [[240, 248], [254, 248], [237, 272], [250, 272]],\n",
    "    [[259, 248], [272, 248], [255, 272], [269, 272]],\n",
    "    [[277, 247], [291, 247], [274, 272], [288, 272]],\n",
    "    [[295, 247], [309, 247], [293, 272], [307, 272]],\n",
    "    [[313, 247], [328, 247], [312, 272], [326, 272]],\n",
    "    [[332, 246], [346, 246], [330, 272], [345, 272]],\n",
    "    [[350, 246], [365, 246], [349, 272], [363, 272]],\n",
    "    [[368, 246], [383, 246], [368, 272], [382, 272]],\n",
    "    [[387, 245], [402, 245], [386, 272], [401, 272]],\n",
    "\n",
    "    [[405, 245], [420, 245], [405, 272], [420, 272]],\n",
    "\n",
    "    [[10, 290], [26, 290], [0, 318], [15, 319]],\n",
    "    [[23, 380], [41, 380], [8, 414], [28, 414]],\n",
    "    [[17, 451], [37, 451], [0, 497], [22, 497]],\n",
    "    [[19, 574], [44, 575], [0, 634], [29, 635]],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    template_spaces = np.float32([\n",
    "        [[2, 0], [17, 0], [1, 22], [17, 22]],\n",
    "        [[8, 2], [34, 3], [1, 43], [26, 44]],\n",
    "    ])\n",
    "\n",
    "    template_files = sorted([f for f in os.listdir(empty_parking_folder) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "    templates = []\n",
    "    for i, template_file in enumerate(template_files):\n",
    "        template_path = os.path.join(empty_parking_folder, template_file)\n",
    "        template_image = cv2.imread(template_path)    \n",
    "        template_image = cv2.cvtColor(template_image, cv2.COLOR_BGR2RGB)\n",
    "        template_image = cv2.GaussianBlur(template_image, (3,3), 0)\n",
    "\n",
    "        x, y, _ = template_image.shape\n",
    "        \n",
    "        dst_points = np.float32([[0, 0], [y, 0], [0, x], [y, x]])\n",
    "\n",
    "        new_image = perspective_transform(template_image, template_spaces[i], dst_points)\n",
    "        new_image = cv2.resize(new_image, (50, 80), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        templates.append(new_image)\n",
    "\n",
    "    frame_files = sorted([f for f in os.listdir(frames_folder) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "\n",
    "    for idx, frame_file in enumerate(frame_files):\n",
    "\n",
    "        if idx == 100:\n",
    "            break\n",
    "        idx += 1\n",
    "        \n",
    "        frame_path = os.path.join(frames_folder, frame_file)\n",
    "        frame = cv2.imread(frame_path)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        for idx, template in enumerate(templates):\n",
    "            x, y, _ = template_image.shape\n",
    "            dst_points = np.float32([[0, 0], [y, 0], [0, x], [y, x]])\n",
    "                \n",
    "            for parking_place_coor in parking_spaces:\n",
    "                frame_copy = perspective_transform(frame, parking_place_coor, dst_points)[0:x, 0:y]\n",
    "                frame_copy = cv2.resize(frame_copy, (50, 80), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "                # show_in_row([frame_copy, template])\n",
    "                \n",
    "                if mse_match(frame_copy, template):\n",
    "                    parking_place_coor[[0, 1, 2, 3]] = parking_place_coor[[0, 1, 3, 2]]\n",
    "                    pts = np.array(parking_place_coor, np.int32)\n",
    "                    parking_place_coor[[0, 1, 2, 3]] = parking_place_coor[[0, 1, 3, 2]]\n",
    "                    pts = pts.reshape((-1,1,2))\n",
    "                    cv2.polylines(frame,[pts],True,(255,0,0), 2)\n",
    "                \n",
    "                    # show_in_row([frame, frame_copy, template])\n",
    "        # show_in_row([frame])\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(output + '/' + frame_file, frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working time: 21.94696068763733 sec.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    main()\n",
    "    print(f\"Working time: {time.time() - start_time} sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
